{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#In this file, track the way that topics change for Washington, Adams, and Jefferson overtime.\n",
      "#  can use either specific time periods that I decide are good, or time periods that are determined systematically.\n",
      "#     also: think about averaging over a year, or over several months.\n",
      "#  alternative: can also use topic modelling to figure this out.\n",
      "\n",
      "\n",
      "#two important time periods to start with for Adams: 1775 - 1777; 1777 - 1778. Over both of these time periods,\n",
      "#  Adams positivity and negativity rise and fall in a linear fashion. Surprisingly, they are positively \n",
      "#  (and not negatively) correlated.\n",
      "\n",
      "# This cell: for both of these time periods, Isolate all letters.\n",
      "\n",
      "time_periods = [(1775, 1777), (1777, 1778)]\n",
      "\n",
      "# open up the adams-date file and isolate the letters with the right dates\n",
      "f = open('adams_fdates_out')\n",
      "dates = f.read().split('\\n')[:-1] #contains dates of all documents on file (not just \"writtenby\")\n",
      "years = [ int(d.split('/')[1]) for d in dates] #isolate years of letts.\n",
      "\n",
      "f_wby = open('adams_writtenby')\n",
      "writtenby = f_wby.read().split('\\n')[:-1] #contains indices of docs written by adams.\n",
      "wby_inds = [ int(w.split('_')[1]) for w in writtenby ]\n",
      "\n",
      "\n",
      "#now, isolate letters in the right time periods in the below list.\n",
      "tpinds = []\n",
      "for i in range(len(time_periods)):\n",
      "    tp = time_periods[i]\n",
      "    letters = [ i for i in wby_inds if ((years[i] >= tp[0]) and (years[i] <= tp[1])) ]\n",
      "    tpinds += [letters]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find out how many letters are in each time period\n",
      "print \"time period: 1775-7: \",\n",
      "print len(tpinds[0])\n",
      "print ''\n",
      "print \"time period: 1777-8: \",\n",
      "print len(tpinds[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "time period: 1775-7:  266\n",
        "\n",
        "time period: 1777-8:  154\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now, perform analysis on the letters indicated in these time periods\n",
      "#start with a PMI analysis.\n",
      "#Recall that PMI = log(P(a^b)/(P(a)P(b))) = **log(p(a | b)/ p(a))**, where a is top-1000, b is \"good\".\n",
      "\n",
      "#this cell: compute the frequency with which every word is mentioned near the word \"good\".\n",
      "#  this will be very important to compute the final PMI score.\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.probability import FreqDist\n",
      "import os\n",
      "\n",
      "#an important constant when searching adams files\n",
      "adams_text_path = os.path.abspath(os.getcwd() + '/../data/crawling/adams_text')\n",
      "\n",
      "\n",
      "#this is the proximity constant\n",
      "prox = 10\n",
      "posdata = []\n",
      "\n",
      "#reconstruct the names of the full list of file indices.\n",
      "fnames = ['adams_' + str(i) for i in tpinds[0]]\n",
      "\n",
      "#build a collection (posdata) of words that occur within 10 words of the word \"good\" in all files\n",
      "for fname in fnames:\n",
      "    f = open(adams_text_path + '/' + fname)\n",
      "    fwds = f.read().split()\n",
      "    fwds = [w.lower() for w in fwds if w.isalpha()]\n",
      "    flen = len(fwds)\n",
      "    for wi in range(len(fwds)):\n",
      "        #if we find the word \"excellent\", store the whole set of words that are within distance \"prox\" of the word.\n",
      "        #we can add other words here later...\n",
      "        # \"excellent\" may work a bit better than \"good\" - it is less commonly used in idioms (i.e. \"good lord!\")\n",
      "        if fwds[wi] == \"excellent\":\n",
      "            posdata += fwds[max(0, wi-prox):min(flen, wi+prox)]\n",
      "    f.close()\n",
      "\n",
      "print posdata[:10]\n",
      "\n",
      "#now, create a freqdist from this collection. This freqdist contains \"freq(w ^ good)\", for all words w.\n",
      "adamsposfd = FreqDist(posdata)\n",
      "#eliminate stopwords\n",
      "for w in stopwords.words('english'):\n",
      "    if w in adamsposfd.keys():\n",
      "        adamsposfd[w] = 0\n",
      "    \n",
      "print ''\n",
      "print adamsposfd.most_common(20)\n",
      "print ''\n",
      "print 'total positive words: ',\n",
      "print len(adamsposfd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['of', 'my', 'the', 'polite', 'prelate', 'did', 'not', 'write', 'to', 'that']\n",
        "\n",
        "[('excellent', 20), ('write', 2), ('young', 2), ('good', 2), ('cannot', 2), ('easily', 2), ('received', 2), ('great', 2), ('friend', 2), ('making', 2), ('sample', 2), ('produces', 1), ('gentleman', 1), ('half', 1), ('merit', 1), ('rifled', 1), ('committee', 1), ('behind', 1), ('skill', 1), ('yet', 1)]\n",
        "\n",
        "total positive words:  199\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "#open the file with all of adams' words & store their freqs in a hashtable.\n",
      "f = open('wf_analysis/adams_wds_nostop')\n",
      "fwds = f.read().split('\\n')[:-1]\n",
      "adamswf = {}\n",
      "for l in fwds:\n",
      "    linearr = l.split(' ')\n",
      "    adamswf[linearr[0]] = int(linearr[1])\n",
      "\n",
      "#compute the final metric: PMI = log(P(a^b)/(P(a)P(b))) = **log(p(w | good)/ p(w))**\n",
      "#  here, let P(w | good) = f(wd ^ good) / f(good). Also, p(w) = f(wd) / total_wc.\n",
      "#  therefore, PMI = log( [f(wd ^ good) / f(good)] * [total_wc / f(wd)] ).\n",
      "#  Since total_wc & f(good) are in every score, we can factor them out, giving:  PMI = log(f(wd^good)/f(wd)).\n",
      "\n",
      "adamspmi = []\n",
      "for w in adamsposfd:\n",
      "    #PMI = log(f(wd^good) / f(wd))\n",
      "    pmi_nlog = float(adamsposfd[w]) / (adamswf[w]+3)\n",
      "    \n",
      "    if pmi_nlog < 0.001:\n",
      "        continue\n",
      "    pmi = math.log(pmi_nlog, 2)\n",
      "    adamspmi += [(w, pmi)]\n",
      "\n",
      "print adamspmi[:20]\n",
      "\n",
      "#sort words by pmi and print out the top ones\n",
      "adamspmi.sort(key = lambda tup: tup[1], reverse=True)\n",
      "print ''\n",
      "print adamspmi[:50]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('gentleman', -8.335390354693924), ('half', -8.63662462054365), ('committee', -7.45121111183233), ('yet', -5.459431618637297), ('write', -5.643856189774724), ('pray', -8.321928094887362), ('young', -7.693486957499325), ('stand', -9.467605550082997), ('might', -5.584962500721157), ('city', -9.124121311829187), ('good', -3.523561956057013), ('friendship', -8.954196310386877), ('means', -7.539158811108031), ('cannot', -4.700439718141093), ('every', -3.4594316186372978), ('easily', -8.079484783826816), ('success', -8.643856189774725), ('always', -7.7414669864011465), ('continue', -8.224001674198107), ('warren', -9.620219825507487)]\n",
        "\n",
        "[('great', -1.8073549220576042), ('would', -2.0), ('upon', -2.584962500721156), ('one', -3.0), ('every', -3.4594316186372978), ('good', -3.523561956057013), ('congress', -3.5849625007211565), ('letter', -3.8073549220576046), ('think', -4.0), ('make', -4.08746284125034), ('made', -4.247927513443586), ('two', -4.321928094887363), ('cannot', -4.700439718141093), ('well', -4.700439718141093), ('received', -4.7279204545632), ('first', -5.20945336562895), ('people', -5.392317422778761), ('yet', -5.459431618637297), ('excellent', -5.469234793667656), ('might', -5.584962500721157), ('friend', -5.599912842187128), ('wish', -5.614709844115209), ('write', -5.643856189774724), ('ever', -5.78135971352466), ('since', -5.807354922057605), ('men', -5.832890014164742), ('little', -6.149747119504682), ('done', -6.523561956057013), ('gentlemen', -6.741466986401148), ('among', -6.78135971352466), ('making', -6.864186144654281), ('things', -7.321928094887362), ('committee', -7.45121111183233), ('told', -7.459431618637297), ('private', -7.499845887083206), ('means', -7.539158811108031), ('franklin', -7.554588851677638), ('young', -7.693486957499325), ('always', -7.7414669864011465), ('arrived', -7.7615512324444795), ('use', -7.787902559391432), ('important', -7.813781191217037), ('doubt', -7.820178962415189), ('character', -7.94251450533924), ('easily', -8.079484783826816), ('colonies', -8.08746284125034), ('line', -8.17492568250068), ('manner', -8.179909090014934), ('continue', -8.224001674198107), ('support', -8.24317398347295)]\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#next, print the above results into a file:\n",
      "#If the central pmi word was \"excellent\"\n",
      "f = open('time_pds_pmi/pmi_excellent_adams_1775_1777', 'w')\n",
      "#If the central pmi word was \"good\"\n",
      "#f = open('time_pds_pmi/pmi_adams_1775_1777', 'w')\n",
      "for w in adamspmi:\n",
      "    f.write(w[0] + ' ' + str(w[1]) + '\\n')\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Here, store the above as a function, that must be run multiple times.\n",
      "# this function will find all the adams files within the two years, \"t0\" and \"t1\", inclusive.\n",
      "#   It will then perform a pmi ranking for all words in those time ranges, and print the results\n",
      "#   of this ranking into a file.\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.probability import FreqDist\n",
      "import os\n",
      "import math\n",
      "\n",
      "def pmi_rank_timerange (t0, t1):\n",
      "    \n",
      "    #-------------------------------------------------------------------------------------#\n",
      "    # Initial data processing: \n",
      "    #an important constant when searching adams files\n",
      "    adams_text_path = os.path.abspath(os.getcwd() + '/../data/crawling/adams_text')       \n",
      "    #this is the proximity constant\n",
      "    prox = 10\n",
      "    \n",
      "    \n",
      "    # open up the adams-date file and isolate the letters with the right dates\n",
      "    f = open('adams_fdates_out')\n",
      "    dates = f.read().split('\\n')[:-1] #contains dates of all documents on file (not just \"writtenby\")\n",
      "    years = [ int(d.split('/')[1]) for d in dates] #isolate years of letts.\n",
      "    \n",
      "    f_wby = open('adams_writtenby')\n",
      "    writtenby = f_wby.read().split('\\n')[:-1] #contains indices of docs written by adams.\n",
      "    wby_inds = [ int(w.split('_')[1]) for w in writtenby ]    \n",
      "    \n",
      "    #now, isolate letters in the right time periods in the below list.\n",
      "    tpinds = [ i for i in wby_inds if ((years[i] >= t0) and (years[i] <= t1)) ]\n",
      "    \n",
      "    #find out how many letters are in this time period\n",
      "    print \"\\n time period: \" + str(t0) + '-' + str(t1) + ': ' + str(len(tpinds))\n",
      "    \n",
      "    \n",
      "    #--------------------------------------------------------------------------------------#\n",
      "    # Compute the frequency with which every word is mentioned near the word \"good\":\n",
      "    #  this will be very important to compute the final PMI score.    \n",
      "     \n",
      "    #reconstruct the names of the full list of file indices.\n",
      "    fnames = ['adams_' + str(i) for i in tpinds]\n",
      "    \n",
      "    #build a collection (posdata) of words that occur within 10 words of the word \"good\" in all files\n",
      "    posdata = []\n",
      "    for fname in fnames:\n",
      "        f = open(adams_text_path + '/' + fname)\n",
      "        fwds = f.read().split()\n",
      "        fwds = [w.lower() for w in fwds if w.isalpha()]\n",
      "        flen = len(fwds)\n",
      "        for wi in range(len(fwds)):\n",
      "            #if we find the word \"excellent\", store the whole set of words that are within distance \"prox\" of the word.\n",
      "            #we can add other words here later...\n",
      "            # \"excellent\" may work a bit better than \"good\" - it is less commonly used in idioms (i.e. \"good lord!\")\n",
      "            if fwds[wi] == \"good\":\n",
      "                posdata += fwds[max(0, wi-prox):min(flen, wi+prox)]\n",
      "        f.close()\n",
      "        \n",
      "    #now, create a freqdist from this collection. This freqdist contains \"freq(w ^ good)\", for all words w.\n",
      "    adamsposfd = FreqDist(posdata)\n",
      "    #eliminate stopwords\n",
      "    for w in stopwords.words('english'):\n",
      "        if w in adamsposfd.keys():\n",
      "            adamsposfd[w] = 0\n",
      "       \n",
      "    \n",
      "    #----------------------------------------------------------------------------------------#\n",
      "    # Compute the final PMI for all words.\n",
      "    \n",
      "    #open the file with all of adams' words & store their freqs in a hashtable.\n",
      "    f = open('wf_analysis/adams_wds_nostop')\n",
      "    fwds = f.read().split('\\n')[:-1]\n",
      "    adamswf = {}\n",
      "    for l in fwds:\n",
      "        linearr = l.split(' ')\n",
      "        adamswf[linearr[0]] = int(linearr[1])\n",
      "    \n",
      "    #compute the final metric: PMI = log(P(a^b)/(P(a)P(b))) = **log(p(w | good)/ p(w))**\n",
      "    #  here, let P(w | good) = f(wd ^ good) / f(good). Also, p(w) = f(wd) / total_wc.\n",
      "    #  therefore, PMI = log( [f(wd ^ good) / f(good)] * [total_wc / f(wd)] ).\n",
      "    #  Since total_wc & f(good) are in every score, we can factor them out, giving:  PMI = log(f(wd^good)/f(wd)).\n",
      "    \n",
      "    adamspmi = []\n",
      "    for w in adamsposfd:\n",
      "        #PMI = log(f(wd^good) / f(wd))\n",
      "        pmi_nlog = float(adamsposfd[w]) / (adamswf[w]+3)\n",
      "        \n",
      "        if pmi_nlog < 0.0001:\n",
      "            continue\n",
      "        pmi = math.log(pmi_nlog, 2)\n",
      "        adamspmi += [(w, pmi)]\n",
      "    \n",
      "    #sort words by pmi and print out the top ones\n",
      "    adamspmi.sort(key = lambda tup: tup[1], reverse=True)\n",
      "    print ''\n",
      "    print adamspmi[:20]\n",
      "    \n",
      "    \n",
      "    #----------------------------------------------------------------------------------------#\n",
      "    # Print the above results into a file:\n",
      "    #If the central pmi word was \"excellent\"\n",
      "    #f = open('time_pds_pmi/pmi_excellent_adams_' + str(t0) + '_' + str(t1), 'w')\n",
      "    #If the central pmi word was \"good\"\n",
      "    f = open('time_pds_pmi/pmi_adams_' + str(t0) + '_' + str(t1), 'w')\n",
      "    for w in adamspmi:\n",
      "        f.write(w[0] + ' ' + str(w[1]) + '\\n')\n",
      "    f.close()\n",
      "\n",
      "\n",
      "# Run the above functions for *every year* in the time periods you want.\n",
      "\"\"\"\n",
      "daterange = range(1775, 1786)\n",
      "for i in daterange:\n",
      "    pmi_rank_timerange(i, i)\n",
      "\"\"\"\n",
      "\n",
      "#run the above function for the full range of Adams' letters.\n",
      "pmi_rank_timerange(1755, 1785)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " time period: 1755-1785: 1644\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('good', 5.1541576855839955), ('may', 4.0), ('would', 3.5849625007211565), ('upon', 3.3219280948873626), ('great', 3.192645077942396), ('shall', 3.1699250014423126), ('much', 2.584962500721156), ('one', 2.0), ('every', 1.5849625007211563), ('must', 1.3439544012173612), ('make', 0.9125371587496607), ('think', 0.9068905956085185), ('congress', 0.874469117916141), ('well', 0.1069152039165119), ('time', 0.0), ('give', -0.10309349296410361), ('letter', -0.10691520391651191), ('us', -0.13750352374993496), ('hope', -0.1979393776119089), ('could', -0.20645087746742632)]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for Adams, plot the number of letters he has written over the significant years of his life.\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      " \n",
      "daterange = range(1775, 1786)\n",
      "#number of letters written in each time period (i.e. year).\n",
      "timepds = [91, 110, 65, 89, 105, 374, 221, 210, 176, 127, 18]\n",
      "\n",
      "#this creates a scatterplot of the above data\n",
      "plt.plot(daterange, timepds, 'ro')\n",
      "plt.xlabel('Year of letter written')\n",
      "plt.ylabel('Number of letters')\n",
      "plt.title('Scatterplot of Letter Frequencies')\n",
      "plt.show()\n",
      "\n",
      "\n",
      "#the below will create a histogram\n",
      "\"\"\"\n",
      "letter_dates = []\n",
      "for i in range(len(timepds)):\n",
      "    letter_dates += timepds[i]*[daterange[i]]\n",
      "\n",
      "plt.hist(letter_dates)\n",
      "plt.xlabel('Year of letter written')\n",
      "plt.ylabel('Number of letters')\n",
      "plt.title('Histogram of Letter Frequencies')\n",
      "plt.show()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "\"\\nletter_dates = []\\nfor i in range(len(timepds)):\\n    letter_dates += timepds[i]*[daterange[i]]\\n\\nplt.hist(letter_dates)\\nplt.xlabel('Year of letter written')\\nplt.ylabel('Number of letters')\\nplt.title('Histogram of Letter Frequencies')\\nplt.show()\\n\""
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#correlation between number of letters written and sentiment\n",
      "\n",
      "#This, I think, shows the powerful impact of a large set of neutral letters (letters with no sentiment).\n",
      "#  perhaps it will be useful to make histograms of each year (or to filter out-low sentiment letters.)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#number of letters written in each time period (i.e. year).\n",
      "#  [outlier at (18 letters, 14 sentiment) excluded.]\n",
      "timepds = [91, 110, 65, 89, 105, 374, 221, 210, 176, 127]\n",
      "senti_level = [10.1, 12.6, 9.9, 10.7, 10.6, 9.0, 9.8, 9.5, 9.9, 10.5]\n",
      "\n",
      "#create a scatterplot of the above data\n",
      "plt.plot(timepds, senti_level, 'ro')\n",
      "plt.xlabel('Number of letters written (per time pd.)')\n",
      "plt.ylabel('Avg. Sentiment level of letters.')\n",
      "plt.title('Scatterplot of letter volume vs. sentiment')\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now, find difference between normal pmi and pmi for a given year.\n",
      "\n",
      "\n",
      "pmi_file_location = 'time_pds_pmi/pmi_adams_'\n",
      "\n",
      "f = open(pmi_file_location + '1755_1785')\n",
      "ftxt = f.read().split('\\n')[:-1]\n",
      "total_pmi={}\n",
      "for l in ftxt:\n",
      "    total_pmi[ l.split(' ')[0] ] = float(l.split(' ')[1])\n",
      "f.close()\n",
      "\n",
      "\n",
      "daterange = range(1775, 1786)\n",
      "year_pmi = {}\n",
      "pmi_diff = []\n",
      "for y in daterange:\n",
      "    f = open(pmi_file_location + str(y) + '_' + str(y))\n",
      "    ftxt = f.read().split('\\n')[:-1]\n",
      "    fpmis = [(l.split(' ')[0], float(l.split(' ')[1])) for l in ftxt]\n",
      "    f.close()\n",
      "    \n",
      "    #store the pmi for every word in the year.\n",
      "    year_pmi[y] = {}\n",
      "    for p in fpmis:\n",
      "        year_pmi[y][p[0]] = p[1]\n",
      "    \n",
      "    min_pmi = min(year_pmi[y].values())\n",
      "    #find the difference between overall pmi and pmi in year y.\n",
      "    for w in total_pmi.keys():\n",
      "        if w in year_pmi[y].keys():\n",
      "            #find relative difference in pmi. If this is a bad metric, can try z-scores as well.\n",
      "            wpmi = year_pmi[y][w]            \n",
      "        else:\n",
      "            wpmi = min_pmi\n",
      "        \n",
      "        #want a positive change to be stored as a positive diff - may need to doublecheck this.\n",
      "        if (total_pmi[w] != 0.0):\n",
      "            pmi_diff += [(w, (wpmi - total_pmi[w]) / abs(total_pmi[w])) ]\n",
      "        \n",
      "    #sort the pmi diffs (descending)\n",
      "    # this means we will see words that are used more often come up first.\n",
      "    pmi_diff.sort(key = lambda tup: tup[1], reverse = True)\n",
      "    \n",
      "    f = open(pmi_file_location + 'diff_' + str(y), 'w')\n",
      "    for t in pmi_diff:\n",
      "        f.write(t[0] + ' ' + str(t[1]) + '\\n')\n",
      "    f.close()         \n",
      "    \n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}